{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1115 17:58:32.711898 4667254208 __init__.py:43] Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import BertTokenizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',add_special_tokens=True,mask_token='@placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_in_list(x):\n",
    "    return ['[MASK]' if i=='@placeholder' else i for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_short_dataset(path,name):\n",
    "    df=pd.read_json(path, lines=True)\n",
    "    df['concat']= df['article']+df['question']\n",
    "    ids_concat = df['concat'].apply((lambda x: tokenizer.tokenize(x)))\n",
    "    label=df['label']\n",
    "    option0 = df['option_0']\n",
    "    option1 = df['option_1']\n",
    "    option2 = df['option_2']\n",
    "    option3 = df['option_3']\n",
    "    option4 = df['option_4']\n",
    "    ids_questions = df['question'].apply((lambda x: tokenizer.tokenize(x)))\n",
    "    ids_context = df['article'].apply((lambda x: tokenizer.tokenize(x)))\n",
    "    ids_concat = df['concat'].apply((lambda x: tokenizer.tokenize(x)))\n",
    "    too_long=[i for i in range(len(ids_concat)) if(len(ids_concat[i]))>508]\n",
    "    for i in too_long:\n",
    "        ids_questions.pop(i)\n",
    "        ids_context.pop(i)\n",
    "        ids_concat.pop(i)\n",
    "        label.pop(i)\n",
    "        option0.pop(i)\n",
    "        option1.pop(i)\n",
    "        option2.pop(i)\n",
    "        option3.pop(i)\n",
    "        option4.pop(i)\n",
    "        \n",
    "    ids_questions = ids_questions.apply((lambda x: replace_in_list(x)))\n",
    "    ids_concat = ids_concat.apply((lambda x: replace_in_list(x)))\n",
    "    short_questions = ids_questions.apply((lambda x: tokenizer.convert_tokens_to_string(x)))\n",
    "    short_context = ids_context.apply((lambda x: tokenizer.convert_tokens_to_string(x)))\n",
    "    short_concat = ids_concat.apply((lambda x: tokenizer.convert_tokens_to_string(x)))\n",
    "    d = {'questions': short_questions, 'context': short_context, 'concat': short_concat,'option_0':option0,\n",
    "                'option_1':option1,'option_2':option2,'option_3':option3,'option_4':option4,'label':label}\n",
    "    df_short = pd.DataFrame(d)\n",
    "    df_short.to_csv('data/clean_training_data/{}.csv'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_short_dataset('data/training_data/Task_1_dev.jsonl','val')\n",
    "get_short_dataset('data/training_data/Task_1_train.jsonl','train')\n",
    "get_short_dataset('data/trail_data/Task_1_Imperceptibility.jsonl','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json('training_data/Task_1_dev.jsonl', lines=True)\n",
    "df['concat']= df['article']+df['question']\n",
    "ids_concat = df['concat'].apply((lambda x: tokenizer.tokenize(x)))\n",
    "options_label_cols={'label':df['label'],\n",
    "                    'option0':df['option_0'],\n",
    "                    'option1':df['option_1'],\n",
    "                    'option2':df['option_2'],\n",
    "                    'option3':df['option_3'],\n",
    "                    'option4':df['option_4']}\n",
    "ids_questions = train_1['question'].apply((lambda x: tokenizer.tokenize(x)))\n",
    "ids_context = train_1['article'].apply((lambda x: tokenizer.tokenize(x)))\n",
    "ids_concat = train_1['concat'].apply((lambda x: tokenizer.tokenize(x)))\n",
    "too_long=[i for i in range(len(ids_concat)) if(len(ids_concat[i]))>508]\n",
    "for i in too_long:\n",
    "    ids_questions.pop(i)\n",
    "    ids_context.pop(i)\n",
    "    ids_concat.pop(i)\n",
    "    for k in options_label_cols.keys():\n",
    "        options_label_cols[k].pop(i)\n",
    "tokenized_questions = ids_questions.apply((lambda x: tokenizer.encode(x)))\n",
    "tokenized_context = ids_context.apply((lambda x: tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_concat=[x+y[1:] for x,y in zip(tokenized_questions,tokenized_context)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1111 10:24:26.506546 4675175872 __init__.py:43] Loading faiss.\n",
      "//anaconda3/lib/python3.7/site-packages/transformers/training_args.py:339: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n",
      "  FutureWarning,\n",
      "2020-11-11 10:24:27.219530: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-11 10:24:27.235183: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff236e3d130 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-11 10:24:27.235209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "W1111 10:24:27.236079 4675175872 run_tf_multiple_choice.py:114] device: cpu, n_replicas: 1, 16-bits training: False\n",
      "I1111 10:24:27.236272 4675175872 run_tf_multiple_choice.py:116] Training/evaluation parameters TFTrainingArguments(output_dir='models_race4', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=True, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=16, per_gpu_eval_batch_size=16, gradient_accumulation_steps=2, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='./runs', logging_first_step=False, logging_steps=100, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name='models_race4', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, tpu_name=None, poly_power=1.0, xla=False)\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForMultipleChoice: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier', 'dropout_37']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "I1111 10:24:31.100397 4675175872 utils_multiple_choice.py:167] Creating features from dataset file at ./data/processed_data\n",
      "I1111 10:24:31.100519 4675175872 utils_multiple_choice.py:258] LOOKING AT ./data/processed_data train\n",
      "I1111 10:24:31.170023 4675175872 utils_multiple_choice.py:175] Training examples: 3113\n",
      "convert examples to features: 0it [00:00, ?it/s]I1111 10:24:31.171949 4675175872 utils_multiple_choice.py:321] Writing example 0 of 3113\n",
      "convert examples to features: 78it [00:02, 30.24it/s]^C\n",
      "convert examples to features: 83it [00:02, 27.74it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"./multiple-choice/run_tf_multiple_choice.py\", line 214, in <module>\n",
      "    main()\n",
      "  File \"./multiple-choice/run_tf_multiple_choice.py\", line 160, in main\n",
      "    if training_args.do_train\n",
      "  File \"/Users/axelbogos/Documents/GitHub/COMP490_Project/multiple-choice/utils_multiple_choice.py\", line 181, in __init__\n",
      "    tokenizer,\n",
      "  File \"/Users/axelbogos/Documents/GitHub/COMP490_Project/multiple-choice/utils_multiple_choice.py\", line 336, in convert_examples_to_features\n",
      "    return_overflowing_tokens=True,\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\", line 2053, in __call__\n",
      "    **kwargs,\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\", line 2123, in encode_plus\n",
      "    **kwargs,\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_utils.py\", line 471, in _encode_plus\n",
      "    first_ids = get_input_ids(text)\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_utils.py\", line 433, in get_input_ids\n",
      "    tokens = self.tokenize(text, **kwargs)\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_utils.py\", line 364, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_utils.py\", line 358, in split_on_tokens\n",
      "    for token in tokenized_text\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_utils.py\", line 358, in <genexpr>\n",
      "    for token in tokenized_text\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_bert.py\", line 221, in _tokenize\n",
      "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_bert.py\", line 418, in tokenize\n",
      "    token = self._run_strip_accents(token)\n",
      "  File \"//anaconda3/lib/python3.7/site-packages/transformers/tokenization_bert.py\", line 428, in _run_strip_accents\n",
      "    text = unicodedata.normalize(\"NFD\", text)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ./multiple-choice/run_tf_multiple_choice.py \\\n",
    "--task_name swag \\\n",
    "--mode sequence-classification \\\n",
    "--model_name_or_path bert-base-uncased \\\n",
    "--data_dir ./data/processed_data \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--learning_rate 5e-5 \\\n",
    "--num_train_epochs 3 \\\n",
    "--max_seq_length 80 \\\n",
    "--per_gpu_eval_batch_size=16 \\\n",
    "--per_gpu_train_batch_size=16 \\\n",
    "--gradient_accumulation_steps 2 \\\n",
    "--eval_steps 100 \\\n",
    "--logging_steps 100 \\\n",
    "--evaluate_during_training \\\n",
    "--output_dir models_race4 \\\n",
    "--logging_dir ./runs \\\n",
    "--overwrite_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 0: syntax error near unexpected token `'modules''\n",
      "/bin/bash: -c: line 0: `help('modules')'\n"
     ]
    }
   ],
   "source": [
    "!help('modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
